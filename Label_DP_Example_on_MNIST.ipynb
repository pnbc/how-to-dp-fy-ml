{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pnbc/how-to-dp-fy-ml/blob/main/Label_DP_Example_on_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label Differential Privacy Example for MNIST Image Classification\n",
        "\n",
        "This colab demonstrate simple baseline algorithms for implementing Label Differential Privacy (Label DP). The colab is based on the [Tensorflow Privacy DP-SGD Example](https://github.com/tensorflow/privacy/blob/master/g3doc/tutorials/classification_privacy.ipynb). For an overview of Differential Privacy and Label Differential Privacy in Deep Learning applications, please see the paper [How to DP-fy ML: A Practical Guide to Machine Learning with Differential Privacy](https://arxiv.org/abs/2303.00654).\n",
        "\n",
        "Label DP is appropriate for the scenarios where only the labels need to be protected. A typical example is in recommender systems, where the candidate items are known, but a user's preferences are sensitive information. Image classification might not be the best application scenario for Label DP. But we build this example on MNIST due to it's easy availability and popularity in machine learning research, and so that it would be easier to compare with the [DP-SGD training colab from Tensorflow Privacy](https://github.com/tensorflow/privacy/blob/master/g3doc/tutorials/classification_privacy.ipynb)."
      ],
      "metadata": {
        "id": "cyDkZFjkwVs1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di7CPCN_wHdn",
        "outputId": "8e07f894-8d30-4e91-d726-e5bbcd5e7611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-privacy\n",
            "  Downloading tensorflow_privacy-0.8.10-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.2/365.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py==1.*,>=1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-privacy) (1.4.0)\n",
            "Collecting attrs~=21.4 (from tensorflow-privacy)\n",
            "  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dm-tree==0.1.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow-privacy) (0.1.8)\n",
            "Collecting dp-accounting==0.4.2 (from tensorflow-privacy)\n",
            "  Downloading dp_accounting-0.4.2-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.6/104.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting immutabledict~=2.2 (from tensorflow-privacy)\n",
            "  Downloading immutabledict-2.2.5-py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: matplotlib~=3.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-privacy) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow-privacy) (1.22.4)\n",
            "Collecting packaging~=22.0 (from tensorflow-privacy)\n",
            "  Downloading packaging-22.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas~=1.4 in /usr/local/lib/python3.10/dist-packages (from tensorflow-privacy) (1.5.3)\n",
            "Collecting parameterized~=0.8 (from tensorflow-privacy)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: scikit-learn==1.*,>=1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-privacy) (1.2.2)\n",
            "Requirement already satisfied: scipy~=1.9 in /usr/local/lib/python3.10/dist-packages (from tensorflow-privacy) (1.10.1)\n",
            "Requirement already satisfied: statsmodels~=0.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow-privacy) (0.13.5)\n",
            "Requirement already satisfied: tensorflow-datasets~=4.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow-privacy) (4.9.2)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.4 in /usr/local/lib/python3.10/dist-packages (from tensorflow-privacy) (2.12.0)\n",
            "Requirement already satisfied: tensorflow-probability~=0.20.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-privacy) (0.20.1)\n",
            "Requirement already satisfied: tensorflow~=2.4 in /usr/local/lib/python3.10/dist-packages (from tensorflow-privacy) (2.12.0)\n",
            "Requirement already satisfied: mpmath~=1.2 in /usr/local/lib/python3.10/dist-packages (from dp-accounting==0.4.2->tensorflow-privacy) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy) (3.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.3->tensorflow-privacy) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.3->tensorflow-privacy) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.3->tensorflow-privacy) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.3->tensorflow-privacy) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.3->tensorflow-privacy) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.3->tensorflow-privacy) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.3->tensorflow-privacy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas~=1.4->tensorflow-privacy) (2022.7.1)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels~=0.13->tensorflow-privacy) (0.5.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (0.4.13)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (2.12.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (0.32.0)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets~=4.5->tensorflow-privacy) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets~=4.5->tensorflow-privacy) (8.1.6)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets~=4.5->tensorflow-privacy) (1.3.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets~=4.5->tensorflow-privacy) (2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets~=4.5->tensorflow-privacy) (5.9.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets~=4.5->tensorflow-privacy) (2.27.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets~=4.5->tensorflow-privacy) (1.13.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets~=4.5->tensorflow-privacy) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets~=4.5->tensorflow-privacy) (4.65.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.20.0->tensorflow-privacy) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.20.0->tensorflow-privacy) (2.2.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.4->tensorflow-privacy) (0.40.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets~=4.5->tensorflow-privacy) (6.0.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets~=4.5->tensorflow-privacy) (3.16.2)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow~=2.4->tensorflow-privacy) (0.2.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets~=4.5->tensorflow-privacy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets~=4.5->tensorflow-privacy) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets~=4.5->tensorflow-privacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets~=4.5->tensorflow-privacy) (3.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.4->tensorflow-privacy) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.4->tensorflow-privacy) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.4->tensorflow-privacy) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.4->tensorflow-privacy) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.4->tensorflow-privacy) (2.3.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets~=4.5->tensorflow-privacy) (1.59.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.4->tensorflow-privacy) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.4->tensorflow-privacy) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.4->tensorflow-privacy) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.4->tensorflow-privacy) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow~=2.4->tensorflow-privacy) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.4->tensorflow-privacy) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.4->tensorflow-privacy) (3.2.2)\n",
            "Installing collected packages: parameterized, packaging, immutabledict, attrs, dp-accounting, tensorflow-privacy\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.1\n",
            "    Uninstalling packaging-23.1:\n",
            "      Successfully uninstalled packaging-23.1\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 23.1.0\n",
            "    Uninstalling attrs-23.1.0:\n",
            "      Successfully uninstalled attrs-23.1.0\n",
            "Successfully installed attrs-21.4.0 dp-accounting-0.4.2 immutabledict-2.2.5 packaging-22.0 parameterized-0.9.0 tensorflow-privacy-0.8.10\n"
          ]
        }
      ],
      "source": [
        "#@title Install Tensorflow Privacy\n",
        "!pip install tensorflow-privacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Common utility functions\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow_privacy\n",
        "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy_lib\n",
        "from tensorflow_privacy.privacy.analysis import compute_noise_from_budget_lib\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "def load_mnist_data():\n",
        "  (train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "  train_data = np.array(train_data, dtype=np.float32).reshape(len(train_data), 28, 28, 1) / 255\n",
        "  test_data = np.array(test_data, dtype=np.float32).reshape(len(test_data), 28, 28, 1) / 255\n",
        "  train_labels = np.array(train_labels, dtype=np.int32)\n",
        "  test_labels = np.array(test_labels, dtype=np.int32)\n",
        "  return (train_data, train_labels), (test_data, test_labels)\n",
        "\n",
        "def get_onehot_labels(train_labels, test_labels):\n",
        "  train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=10)\n",
        "  test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)\n",
        "  return train_labels, test_labels\n",
        "\n",
        "def compile_model(learning_rate, dpsgd_config):\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(16, 8, strides=2, padding='same',\n",
        "                             activation='relu', input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPool2D(2, 1),\n",
        "      tf.keras.layers.Conv2D(32, 4, strides=2, padding='valid', activation='relu'),\n",
        "      tf.keras.layers.MaxPool2D(2, 1),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(32, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)])\n",
        "\n",
        "  if dpsgd_config is None:\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "  else:\n",
        "    optimizer = tensorflow_privacy.DPKerasAdamOptimizer(\n",
        "        l2_norm_clip=dpsgd_config['l2_norm_clip'],\n",
        "        noise_multiplier=dpsgd_config['noise_multiplier'],\n",
        "        num_microbatches=dpsgd_config['num_microbatches'],\n",
        "        learning_rate=learning_rate)\n",
        "\n",
        "  loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True, reduction=tf.losses.Reduction.NONE)\n",
        "  model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "ZNxdTUtNxnJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DP-SGD Training"
      ],
      "metadata": {
        "id": "4P6ha316yOrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_dpsgd_train(privacy_budget, l2_norm_clip=1.5, epochs=3, batch_size=250,\n",
        "                    learning_rate=0.001, delta=1e-5):\n",
        "  (train_data, train_labels), (test_data, test_labels) = load_mnist_data()\n",
        "  train_labels, test_labels = get_onehot_labels(train_labels, test_labels)\n",
        "  noise_multiplier = compute_noise_from_budget_lib.compute_noise(\n",
        "      len(train_data), batch_size, privacy_budget, epochs, delta, noise_lbd=1e-5)\n",
        "\n",
        "  dpsgd_config = {'l2_norm_clip': l2_norm_clip, 'noise_multiplier': noise_multiplier,\n",
        "                  'num_microbatches': batch_size}\n",
        "  model = compile_model(learning_rate, dpsgd_config)\n",
        "  return model.fit(train_data, train_labels, epochs=epochs,\n",
        "                   validation_data=(test_data, test_labels), batch_size=batch_size)"
      ],
      "metadata": {
        "id": "rln3dMEPySoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dpsgd_train_result = run_dpsgd_train(1.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn9htCKY1-SR",
        "outputId": "8bac2719-18b4-4bf9-e170-ca3aad33584d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "DP-SGD with sampling rate = 0.417% and noise_multiplier = 1.0188458598723718 iterated over 720 steps satisfies differential privacy with eps = 1 and delta = 1e-05.\n",
            "Epoch 1/3\n",
            "240/240 [==============================] - 70s 237ms/step - loss: 1.3896 - accuracy: 0.5591 - val_loss: 0.6384 - val_accuracy: 0.8015\n",
            "Epoch 2/3\n",
            "240/240 [==============================] - 57s 239ms/step - loss: 0.5420 - accuracy: 0.8379 - val_loss: 0.4532 - val_accuracy: 0.8698\n",
            "Epoch 3/3\n",
            "240/240 [==============================] - 58s 240ms/step - loss: 0.4373 - accuracy: 0.8835 - val_loss: 0.3993 - val_accuracy: 0.8961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label DP with Randomized Response\n",
        "\n",
        "Randomized Response is one of the simplest method to achieve Label DP for classification problems.\n",
        "\n",
        "**Remarks**\n",
        "\n",
        "1. Randomized Response (RR) is actually a Local DP algorithm that privatize the training data -- it works by randomizing the label of each training example. After privitizing the training labels, the dataset can be used to train a model. The privacy cost does not depend on the number of model training epochs. One can also train multiple models on the data or release the data publicly without violating the DP guarantee.\n",
        "2. Since RR works by transforming the training labels, it can be implemented without any modification to an existing non-private machine learning pipeline. However, the training dynamics with noisy labels might be quite different from non-private training, so the optimal hyperparameters might need to be changed.\n",
        "3. For $K$-class classification, the probability that a training label remains unchanged after RR transformation is $e^\\varepsilon/(e^\\varepsilon + K-1)$, where $\\varepsilon$ is the privacy budget. Therefore, RR usually does not work very well for problems with large number of classes and / or small privacy budget.\n"
      ],
      "metadata": {
        "id": "-o8OvVOO3HDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def randomized_response(train_labels, privacy_budget, seed=1234, num_classes=10):\n",
        "  rs = np.random.default_rng(seed)\n",
        "  deltas = 1 + rs.integers(0, num_classes-1, size=len(train_labels))\n",
        "  p_unchanged = 1 / (1 + (num_classes-1) * np.exp(-privacy_budget))\n",
        "  deltas[rs.random(len(deltas)) <= p_unchanged] = 0\n",
        "  print(f'RR with epsilon={privacy_budget}, {100*(1-(deltas == 0).sum()/len(deltas)):.2f}% of the labels are flipped')\n",
        "  return (train_labels + deltas) % num_classes\n",
        "\n",
        "def run_randomized_response(privacy_budget, epochs=10, batch_size=250, learning_rate=0.001, seed=1234):\n",
        "  (train_data, train_labels), (test_data, test_labels) = load_mnist_data()\n",
        "  train_labels = randomized_response(train_labels, privacy_budget, seed=seed)\n",
        "  train_labels, test_labels = get_onehot_labels(train_labels, test_labels)\n",
        "  model = compile_model(learning_rate, dpsgd_config=None)\n",
        "  return model.fit(train_data, train_labels, epochs=epochs,\n",
        "                   validation_data=(test_data, test_labels), batch_size=batch_size)"
      ],
      "metadata": {
        "id": "U3yUOsES2Bix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rr_train_result = run_randomized_response(1.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eui4R7Rh7FD9",
        "outputId": "06dee1cd-7384-4616-a5fe-65353f85b249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RR with epsilon=1.0, 76.69% of the labels are flipped\n",
            "Epoch 1/10\n",
            "240/240 [==============================] - 4s 6ms/step - loss: 2.2777 - accuracy: 0.1785 - val_loss: 1.8253 - val_accuracy: 0.8509\n",
            "Epoch 2/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 2.2550 - accuracy: 0.2160 - val_loss: 1.6862 - val_accuracy: 0.9135\n",
            "Epoch 3/10\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 2.2457 - accuracy: 0.2227 - val_loss: 1.6059 - val_accuracy: 0.9366\n",
            "Epoch 4/10\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 2.2399 - accuracy: 0.2243 - val_loss: 1.6168 - val_accuracy: 0.9323\n",
            "Epoch 5/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 2.2354 - accuracy: 0.2252 - val_loss: 1.5921 - val_accuracy: 0.9350\n",
            "Epoch 6/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 2.2314 - accuracy: 0.2268 - val_loss: 1.6203 - val_accuracy: 0.9292\n",
            "Epoch 7/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 2.2278 - accuracy: 0.2270 - val_loss: 1.5478 - val_accuracy: 0.9497\n",
            "Epoch 8/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 2.2245 - accuracy: 0.2271 - val_loss: 1.5453 - val_accuracy: 0.9453\n",
            "Epoch 9/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 2.2207 - accuracy: 0.2277 - val_loss: 1.5522 - val_accuracy: 0.9344\n",
            "Epoch 10/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 2.2168 - accuracy: 0.2283 - val_loss: 1.5450 - val_accuracy: 0.9301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Randomized Response with Prior\n",
        "\n",
        "Randomized Response with Prior (RR-with-Prior) was introduced in [Deep Learning with Label Differential Privacy](https://arxiv.org/abs/2102.06062). It reduces the RR noises by utilizing a (public) prior on the label distribution. There are various ways to obtain such prior depending on the underlying problem. Here we present a simple KMeans clustering based approach to query the prior, and refer the readers to the [paper](https://arxiv.org/abs/2102.06062) for other approaches. A similar approach has been developed for regression labels in [https://arxiv.org/abs/2212.06074](https://arxiv.org/abs/2212.06074).\n",
        "\n",
        "**Remarks**\n",
        "1. This particular algorithm demonstrated here is no longer local DP because it queries aggregate label information in a central server to construct the priors. However, if local DP is required, this mechanism can also be implemented in the (interactive) local DP setting by adding noise locally when constructing the prior. This would lead to more noises being added, but could still be feasible in some applications (especially when the number of examples per class is large).\n",
        "2. In the clustering based approach for querying priors, we used the raw pixel representations to run clustering, which works reasonably well for the MNIST dataset. For more challenging image datasets, it generally helps to use representations from a self-supervised learning (without access to the raw labels) trained model."
      ],
      "metadata": {
        "id": "h6GkEewRANdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def cluster_train_data(train_data, n_clusters=100):\n",
        "  train_data = train_data.reshape((train_data.shape[0], -1))\n",
        "  train_data_low_dim = PCA(50).fit_transform(train_data)\n",
        "  kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=\"auto\").fit(train_data_low_dim)\n",
        "  return kmeans.labels_\n",
        "\n",
        "def query_cluster_based_label_priors(cluster_id, train_labels, query_privacy_budget, n_classes=10):\n",
        "  priors = np.zeros((len(train_labels), n_classes))\n",
        "  for id in np.unique(cluster_id):\n",
        "    histogram = np.bincount(train_labels[cluster_id == id], minlength=n_classes)\n",
        "    noisy_histogram = histogram + scipy.stats.dlaplace.rvs(query_privacy_budget/2, size=n_classes)\n",
        "    noisy_histogram = np.maximum(noisy_histogram, 0)  # clip negative values\n",
        "    prior = noisy_histogram / np.maximum(1e-10, np.sum(noisy_histogram))  # normalize\n",
        "    priors[cluster_id == id, :] = prior[np.newaxis, :]\n",
        "  return priors\n",
        "\n",
        "def rr_with_prior(prior, eps, y, rs):\n",
        "  idx_sort = np.flipud(np.argsort(prior))\n",
        "  prior_sorted = prior[idx_sort]\n",
        "  tmp = np.exp(-eps)\n",
        "  wks = [np.sum(prior_sorted[:(k+1)]) / (1 + (k-1)*tmp) for k in range(len(prior))]\n",
        "  optim_k = np.argmax(wks) + 1\n",
        "\n",
        "  adjusted_prior = np.zeros_like(prior) + tmp / (1 + (optim_k-1)*tmp)\n",
        "  adjusted_prior[y] = 1 / (1 + (optim_k-1)*tmp)\n",
        "  adjusted_prior[idx_sort[optim_k:]] = 0\n",
        "  adjusted_prior /= np.sum(adjusted_prior)  # renorm in case y not in topk\n",
        "  rr_label = rs.choice(len(prior), p=adjusted_prior)\n",
        "  return rr_label\n",
        "\n",
        "def run_randomized_response_with_prior(privacy_budget, budget_for_prior=0.1, epochs=10,\n",
        "                                       batch_size=250, learning_rate=0.001, seed=1234):\n",
        "  (train_data, train_labels), (test_data, test_labels) = load_mnist_data()\n",
        "  # Note there are many different ways to get priors, here we use kmeans\n",
        "  cluster_id = cluster_train_data(train_data, n_clusters=200)\n",
        "  priors = query_cluster_based_label_priors(cluster_id, train_labels, budget_for_prior)\n",
        "  remaining_budget = privacy_budget - budget_for_prior\n",
        "  rs = np.random.default_rng(seed=seed)\n",
        "  original_train_labels = train_labels\n",
        "  train_labels = np.vectorize(lambda i: rr_with_prior(priors[i], 1.95, train_labels[i], rs))(np.arange(len(train_labels)))\n",
        "  n_flipped = np.sum(train_labels != original_train_labels)\n",
        "  print(f'RRWithPrior with epsilon={privacy_budget}, {100*n_flipped/len(train_labels):.2f}% of the labels are flipped')\n",
        "  train_labels, test_labels = get_onehot_labels(train_labels, test_labels)\n",
        "  model = compile_model(learning_rate, dpsgd_config=None)\n",
        "  return model.fit(train_data, train_labels, epochs=epochs,\n",
        "                   validation_data=(test_data, test_labels), batch_size=batch_size)"
      ],
      "metadata": {
        "id": "laBASOmRAPBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rr_with_prior_train_result = run_randomized_response_with_prior(1.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un_vOTIxHFk1",
        "outputId": "9f6e9661-d7f9-4176-f10e-560337c88cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RRWithPrior with epsilon=1.0, 12.48% of the labels are flipped\n",
            "Epoch 1/10\n",
            "240/240 [==============================] - 4s 7ms/step - loss: 0.8951 - accuracy: 0.7681 - val_loss: 0.2582 - val_accuracy: 0.9410\n",
            "Epoch 2/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5617 - accuracy: 0.8693 - val_loss: 0.2291 - val_accuracy: 0.9539\n",
            "Epoch 3/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5296 - accuracy: 0.8746 - val_loss: 0.2310 - val_accuracy: 0.9502\n",
            "Epoch 4/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5052 - accuracy: 0.8782 - val_loss: 0.2375 - val_accuracy: 0.9534\n",
            "Epoch 5/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.4906 - accuracy: 0.8796 - val_loss: 0.2294 - val_accuracy: 0.9515\n",
            "Epoch 6/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.4766 - accuracy: 0.8824 - val_loss: 0.2493 - val_accuracy: 0.9434\n",
            "Epoch 7/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.4672 - accuracy: 0.8819 - val_loss: 0.2244 - val_accuracy: 0.9460\n",
            "Epoch 8/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.4590 - accuracy: 0.8828 - val_loss: 0.2269 - val_accuracy: 0.9515\n",
            "Epoch 9/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.4471 - accuracy: 0.8840 - val_loss: 0.2302 - val_accuracy: 0.9496\n",
            "Epoch 10/10\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.4395 - accuracy: 0.8846 - val_loss: 0.2041 - val_accuracy: 0.9532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Remarks\n",
        "\n",
        "- This colab serves as an example of how to enable Label DP in a deep learning classification pipeline. The training setups and hyperparameters might not be optimal. For simplicity, we only demonstrated two basic Label DP algorithms, please refer to  the paper [How to DP-fy ML: A Practical Guide to Machine Learning with Differential Privacy](https://arxiv.org/abs/2303.00654) for references on other Label DP algorithms suitable for different scenarios.\n",
        "\n",
        "- Label DP results are **not** directly comparable with DP-SGD, because Label DP only protects the labels while DP-SGD protect both the inputs and labels. Therefore, intuitively Label DP should be easier under the same privacy budget ($\\varepsilon$). In practice, this might not necessarily be true, depending on the specific algorithms being used in comparison. For example, (vanilla) randomized response tends to perform poorly when the number of classes are  large or when the privacy budget ($\\varepsilon$) is small.\n"
      ],
      "metadata": {
        "id": "QeL1ZuNsT4qw"
      }
    }
  ]
}